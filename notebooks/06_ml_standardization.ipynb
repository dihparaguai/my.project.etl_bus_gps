{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "134844b9",
   "metadata": {},
   "source": [
    "# Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59130f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9beaab31",
   "metadata": {},
   "source": [
    "# Ambiente de Execução: Colab X VSCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa51ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Usar no Google Colab\n",
    "# from google.colab import auth\n",
    "# auth.authenticate_user()\n",
    "# path_folder_bronze = '/content/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137dd13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar no VSCode\n",
    "path_folder_silver = os.path.abspath('../data/temp/silver')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1afa154",
   "metadata": {},
   "source": [
    "# Leitura dos Dados Limpos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad64e7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_year_month(date): # Função para extrair o ano e o mês de uma data\n",
    "    return date.strftime('%y%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ef5024",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_month = extract_year_month(pd.to_datetime('2017-06-01'))  # Exemplo de uso da função, como se fosse o dia 01 de junho de 2017\n",
    "\n",
    "print(f'Year-Month: {year_month}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f1f526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_cleaned(path_folder_silver, file_name_silver): # Função para ler o arquivo CSV limpo\n",
    "    df = pd.read_csv(os.path.join(path_folder_silver, file_name_silver))\n",
    "    \n",
    "    print(f'Arquivo \"{file_name_silver}\" lido.')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2924aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_silver = f'mta_{year_month}_cleaned.csv'\n",
    "\n",
    "df = read_csv_cleaned(path_folder_silver, file_name_silver)\n",
    "\n",
    "display(df.head(15))\n",
    "display(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd91000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_columns(df, columns_to_remove): # Função para remover colunas do DataFrame\n",
    "    df = df.drop(columns=columns_to_remove)\n",
    "    print(f'Colunas removidas: {columns_to_remove}')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eff3450",
   "metadata": {},
   "source": [
    "# Remoção de colunas não necessárias e de outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e8c0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml = remove_columns(df, ['RecordedTimeRange', 'ScheduledTimeRange'])\n",
    "\n",
    "display(df_ml.head(15))\n",
    "display(df_ml.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689b3199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_iqr(df, column_name): # Função para remover outliers usando o método IQR (Intervalo Interquartil)\n",
    "    q1 = df[column_name].quantile(0.25)\n",
    "    q3 = df[column_name].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    print(f'Limite inferior: {lower_bound}, Limite superior: {upper_bound}')\n",
    "\n",
    "    df = df[(df[column_name] > lower_bound) & (df[column_name] < upper_bound)]\n",
    "    \n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    print(f'Outliers removidos da coluna \"{column_name}\" usando IQR.')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92bd193",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml = remove_outliers_iqr(df_ml, 'DiffArrivalMins')\n",
    "\n",
    "display(df_ml.head(15))\n",
    "display(df_ml.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445870dd",
   "metadata": {},
   "source": [
    "# Transformação de colunas de data e hora em numéricas para ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2363335c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_timedelta_to_seconds(df, column_name): # Função para transformar uma coluna de timedelta em segundos\n",
    "    df[column_name] = pd.to_timedelta(df[column_name])\n",
    "    df[column_name] = df[column_name].dt.total_seconds().astype(int)\n",
    "    print(f'Coluna \"{column_name}\" transformada em segundos.')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d675507c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml = transform_timedelta_to_seconds(df_ml, 'RecordedAtTime')\n",
    "df_ml = transform_timedelta_to_seconds(df_ml, 'ScheduledArrivalTime')\n",
    "\n",
    "display(df_ml.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0207877e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_date_to_days(df, column_name): # Função para transformar uma coluna de date em dias desde uma data de referência\n",
    "    df[column_name] = pd.to_datetime(df[column_name])\n",
    "    \n",
    "    stdate = pd.Timestamp('2017-01-01')  # Data de referência para o cálculo dos dias\n",
    "    \n",
    "    df['RecordedAtDate'] = (df['RecordedAtDate'] - stdate).dt.total_seconds()\n",
    "    df['RecordedAtDate'] = df['RecordedAtDate'] // (24 * 3600)  # Convertendo para dias\n",
    "    df['RecordedAtDate'] = df['RecordedAtDate'].astype(int)\n",
    "    \n",
    "    print(f'Coluna \"{column_name}\" transformada para dias desde a data de referência.')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62644a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml = transform_date_to_days(df_ml, 'RecordedAtDate')\n",
    "\n",
    "display(df_ml.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f651a1",
   "metadata": {},
   "source": [
    "# Transformação de colunas categoricas em numéricas com hash "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27138af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_encode_column(df, column_name): # Função para aplicar o HashingEncoder em uma coluna específica\n",
    "    \n",
    "    num_unique = df[column_name].nunique()\n",
    "    print(f'Número de valores únicos na coluna \"{column_name}\": {num_unique}')\n",
    "    \n",
    "    # Determina o número de componentes para o HashingEncoder usando a maior potência de 2 menor ou igual ao número de valores únicos\n",
    "    n_components = 1\n",
    "    while True:\n",
    "        if 2 ** n_components > num_unique:\n",
    "            n_components += -1\n",
    "            break\n",
    "        n_components += 1\n",
    "        \n",
    "    n_components = 1 if n_components < 1 else n_components # Garantir que n_components seja pelo menos 1\n",
    "    print(f'Número de componentes para HashingEncoder: {n_components}')\n",
    "    \n",
    "    encoder = ce.HashingEncoder(cols=[column_name], n_components=n_components)  # Ajuste n_components conforme necessário\n",
    "    df = encoder.fit_transform(df)\n",
    "    \n",
    "    df = df.rename(columns={\n",
    "        f'col_{i}': f'{column_name}_hash_{i}' \n",
    "        for i in range(n_components)\n",
    "    })\n",
    "    \n",
    "    print(f'Coluna \"{column_name}\" codificada com HashingEncoder.')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524c900a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml = hash_encode_column(df_ml, 'PublishedLineName')\n",
    "\n",
    "display(df_ml.head(15))\n",
    "display(df_ml.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9f482f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml = hash_encode_column(df_ml, 'VehicleRef')\n",
    "\n",
    "display(df_ml.head(15))\n",
    "display(df_ml.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d611085",
   "metadata": {},
   "source": [
    "# Normalização das escalas das colunas de data e hora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3075f716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_columns(df, columns_names): # Função para padronizar colunas numéricas, ou seja, normalizar as escalas\n",
    "    scaler = StandardScaler()\n",
    "    df[columns_names] = scaler.fit_transform(df[columns_names])\n",
    "    print(f'Colunas: \"{columns_names}\" padronizadas.')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fb8d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml = standardize_columns(df_ml, ['RecordedAtTime', 'ScheduledArrivalTime', 'RecordedAtDate'])\n",
    "\n",
    "display(df_ml.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163ceb04",
   "metadata": {},
   "source": [
    "# Salvar dados normalizados e pré-processados para ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d6facb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_parquet(df, path_folder_gold_ml, file_name_gold_ml): # Função para salvar o DataFrame em formato Parquet\n",
    "    df.to_parquet(os.path.join(path_folder_gold_ml, file_name_gold_ml), engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379a65b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_folder_gold_ml = os.path.abspath(f'../data/temp/gold/ml/')\n",
    "file_name_gold_ml = f'mta_{year_month}_ml.parquet'\n",
    "\n",
    "save_to_parquet(df_ml, path_folder_gold_ml, file_name_gold_ml)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
